# AI Research Studies

This repository contains empirical and theoretical studies in artificial
intelligence, with a focus on generalization, interpretability, reasoning,
uncertainty, causality, and fairness. The projects emphasize evaluation,
analysis, and responsible AI practices.

## Project 1: Neural Network Generalization
An empirical study of how model capacity and training data size affect
generalization behaviour in neural networks. Results are analyzed using
learning curves and repeated experiments to study biasâ€“variance trade-offs.

## Project 2: Stability and Faithfulness of Model Explanations
An evaluation-driven study of model interpretability, analyzing the stability
of feature importance explanations across runs, agreement between models, and
faithfulness through controlled feature-removal tests.

## Project 3: Reasoning with Soft Logical Constraints
A logic-based study exploring reasoning under conflicting rules using soft
constraints. Logical worlds are evaluated using weighted penalties to identify
optimal explanations under inconsistency.

## Project 4: Uncertainty Quantification in Probabilistic Models
A probabilistic study comparing frequentist and Bayesian-style approaches to
classification by analyzing predictive uncertainty, calibration behaviour,
and proper scoring rules.

## Project 5: Counterfactual Reasoning in Causal Models
A causal inference study demonstrating confounding, interventional effects,
and counterfactual outcomes, highlighting the difference between observational
correlations and causal reasoning.

## Project 6: Fairness and Bias in Machine Learning
An analysis of algorithmic fairness using demographic parity and equal
opportunity metrics, examining trade-offs between predictive accuracy and
group-level bias.

Each project folder contains code and figures corresponding to the experiments
described above.
