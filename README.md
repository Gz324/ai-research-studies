# AI Research Studies

This repository contains empirical and theoretical studies in artificial
intelligence, with a focus on generalization, interpretability, reasoning, and
uncertainty. The projects emphasize evaluation, analysis, and methodological
clarity.

## Project 1: Neural Network Generalization
An empirical study of how model capacity and training data size affect
generalization behaviour in neural networks. Results are analyzed using
learning curves and repeated experiments to study biasâ€“variance trade-offs.

## Project 2: Stability and Faithfulness of Model Explanations
An evaluation-driven study of model interpretability, analyzing the stability
of feature importance explanations across runs, agreement between models, and
faithfulness through controlled feature-removal tests.

## Project 3: Reasoning with Soft Logical Constraints
A logic-based study exploring reasoning under conflicting rules using soft
constraints. Logical worlds are evaluated using weighted penalties to identify
optimal explanations under inconsistency.

## Project 4: Uncertainty Quantification in Probabilistic Models
A probabilistic study comparing frequentist and Bayesian-style approaches to
classification by analyzing predictive uncertainty, calibration behaviour,
and proper scoring rules.

Each project folder contains code and figures corresponding to the experiments
described above.

