# AI Research Studies

This repository contains empirical and theoretical studies in artificial
intelligence, focusing on learning behaviour, reasoning, uncertainty,
fairness, robustness, causality, and optimization. The projects emphasize
analysis-driven experimentation and strong conceptual grounding.

## Project 1: Neural Network Generalization
An empirical study of how model capacity and dataset size affect generalization
behaviour in neural networks, analyzed using learning curves and repeated
experiments.

## Project 2: Stability and Faithfulness of Model Explanations
An evaluation of interpretability methods by studying explanation stability
across runs and faithfulness through controlled feature perturbations.

## Project 3: Reasoning with Soft Logical Constraints
A logic-based reasoning study using soft constraints to handle conflicting
rules and evaluate optimal explanations under inconsistency.

## Project 4: Uncertainty Quantification in Probabilistic Models
A probabilistic analysis comparing predictive uncertainty and calibration
behaviour under different modeling assumptions.

## Project 5: Counterfactual Reasoning in Causal Models
A causal inference study demonstrating the difference between observational
correlation, interventions, and counterfactual outcomes.

## Project 6: Fairness and Bias in Machine Learning
An analysis of algorithmic fairness using demographic parity and equal
opportunity metrics, highlighting accuracyâ€“fairness trade-offs.

## Project 7: Robustness under Distribution Shift
An empirical robustness study evaluating how model performance degrades under
controlled input perturbations.

## Project 8: Optimization Dynamics and Convergence
An empirical analysis comparing gradient descent and stochastic gradient
descent, focusing on convergence speed, stability, and optimization noise.

Each project folder contains the code and figures corresponding to the
experiments described above.
